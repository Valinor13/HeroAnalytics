{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938fecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import speech\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'client_service_key.json'\n",
    "speech_client = speech.SpeechClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a35f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello_gcs(event, context):\n",
    "    \"\"\"Triggered by a change to a Cloud Storage bucket.\n",
    "    Args:\n",
    "         event (dict): Event payload.\n",
    "         context (google.cloud.functions.Context): Metadata for the event.\n",
    "    \"\"\"\n",
    "    file = event\n",
    "    print(f\"Processing file: {file['name']}.\")\n",
    "    print(event)\n",
    "\n",
    "    if file['name'].endswith(\".wav\"):\n",
    "        media_uri = f\"gs://heroxr-development.appspot.com/{file['name']}\"\n",
    "        transcription, magnitude, score = process_audio_file(media_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6191e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_file(media_uri):\n",
    "    \"\"\"Processes .wav files that are added to the bucket\n",
    "    Args:\n",
    "        media_uri (str): path to file within bucket\n",
    "    \"\"\"\n",
    "    transcription = speech_to_text(media_uri)\n",
    "    magnitude, score = analyze_sentiment(transcription)\n",
    "    \n",
    "    return transcription, magnitude, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e354985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(transcription):\n",
    "    \"\"\"Analyzes the sentiment of a transcribed audio file.\n",
    "    Args:\n",
    "        transcription (str): the transcription to analyze\n",
    "    \"\"\"\n",
    "    from google.cloud import language_v1\n",
    "\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "    document = language_v1.Document(\n",
    "        content=transcription, type_=language_v1.Document.Type.PLAIN_TEXT\n",
    "    )\n",
    "    annotations = client.analyze_sentiment(request={'document': document})\n",
    "\n",
    "    magnitude = annotations.document_sentiment.magnitude\n",
    "    score = annotations.document_sentiment.score\n",
    "    \n",
    "    return magnitude, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9415af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text(media_uri):\n",
    "    \"\"\"Converts .wav files to text\n",
    "    Args:\n",
    "        medai_uri (str): path to file within bucket\n",
    "    \"\"\"\n",
    "    from google.cloud import speech\n",
    "\n",
    "    speech_client = speech.SpeechClient()\n",
    "    long_audio = speech.RecognitionAudio(uri=media_uri)\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        sample_rate_hertz=44100, # Change to match sampling rate of unity files\n",
    "        enable_automatic_punctuation=True,\n",
    "        language_code='en-US',\n",
    "        audio_channel_count=2\n",
    "    )\n",
    "\n",
    "    # We use long_running_recognize because media files might be over 1 minute in length\n",
    "    operation = speech_client.long_running_recognize(\n",
    "        config=config,\n",
    "        audio=long_audio\n",
    "    )\n",
    "    response = operation.result(timeout=90)\n",
    "\n",
    "    transcription = \"\"\n",
    "    for i, result in enumerate(response.results):\n",
    "        # If/else determines when to add spaces for concatenation\n",
    "        # There will be no trailing space added for the final transcription segment\n",
    "        if i == (len(response.results) - 1):\n",
    "            transcription += result.alternatives[0].transcript\n",
    "        else:\n",
    "            transcription += result.alternatives[0].transcript + ' '\n",
    "\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfc5a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'client_service_key.json'\n",
    "\n",
    "\n",
    "def speech_to_text(media_uri):\n",
    "    \"\"\"Converts .wav files to text\n",
    "    Args:\n",
    "        medai_uri (str): path to file within bucket\n",
    "    \"\"\"\n",
    "    from google.cloud import speech\n",
    "\n",
    "    speech_client = speech.SpeechClient()\n",
    "    long_audio = speech.RecognitionAudio(uri=media_uri)\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        sample_rate_hertz=48000, # Change to match sampling rate of unity files\n",
    "        enable_automatic_punctuation=True,\n",
    "        language_code='en-US'#,\n",
    "        #audio_channel_count=2\n",
    "    )\n",
    "\n",
    "    # We use long_running_recognize because media files might be over 1 minute in length\n",
    "    operation = speech_client.long_running_recognize(\n",
    "        config=config,\n",
    "        audio=long_audio\n",
    "    )\n",
    "    response = operation.result(timeout=90)\n",
    "\n",
    "    transcription = \"\"\n",
    "    for i, result in enumerate(response.results):\n",
    "        # If/else determines when to add spaces for concatenation\n",
    "        # There will be no trailing space added for the final transcription segment\n",
    "        if i == (len(response.results) - 1):\n",
    "            transcription += result.alternatives[0].transcript\n",
    "        else:\n",
    "            transcription += result.alternatives[0].transcript + ' '\n",
    "\n",
    "    return transcription\n",
    "#     transcription = response.results.alternatives[0].transcript.join(' ')\n",
    "    \n",
    "#     return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b08d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_uri = \"gs://hero-speech-to-text-media-files/testing_converted.wav\"\n",
    "transcription = speech_to_text(media_uri=media_uri)\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f5ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = \"In 2006 Geoffrey, Hinton at all published a paper showing how to train, a deep neural network. If pull up recognizing handwritten, digits with the state-of-the-art Precision. They branded this technique deep learning. A deep neural network is a very simplified model of our cerebral. Cortex composed, of a stack of layers of artificial neurons. Training, a deep neural, net was widely considered impossible at the time. And most researchers had abandoned, the idea in the late 1990s. This paper revived the interest of the scientific community. And before long, many new papers, demonstrated that deep learning was not only possible, but capable of mind-blowing achievements that no other machine learning techniques, could hope to match This enthusiasm soon extended too many other areas of machine learning a decade or so, later, machine learning has conquered the industry. It is at the heart of much of the Magic. In today's high-tech products, ranking, your web, search results powering your smartphone speech, recognition, recommending videos and beating the world champion at the game of go before, you know, it will be driving your car.\"\n",
    "magnitude, score = analyze_sentiment(transcription)\n",
    "print(f\"magnitude: {magnitude}, score: {score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
